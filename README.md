# Emirhans_Method_Deepfake
BLIP is a VLP (Vision-Language Pre-training) framework that excels in both vision-language understanding and generation tasks using a multimodal mixture of encoder-decoder model and a novel captioning and filtering method for handling noisy data. In this project, we will try to use BLIP in deepfake detection
